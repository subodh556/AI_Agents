{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in d:\\condaa\\envs\\atlas\\lib\\site-packages (0.2.69)\n",
      "Requirement already satisfied: langchain in d:\\condaa\\envs\\atlas\\lib\\site-packages (0.3.17)\n",
      "Requirement already satisfied: langchain-openai in d:\\condaa\\envs\\atlas\\lib\\site-packages (0.3.3)\n",
      "Requirement already satisfied: openai in d:\\condaa\\envs\\atlas\\lib\\site-packages (1.61.0)\n",
      "Requirement already satisfied: python-dotenv in d:\\condaa\\envs\\atlas\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: capture in d:\\condaa\\envs\\atlas\\lib\\site-packages (0.1)\n",
      "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from langgraph) (0.3.33)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from langgraph) (2.0.10)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from langgraph) (0.1.51)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from langchain) (2.0.37)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from langchain) (3.11.11)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from langchain) (2.2.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from langchain) (2.10.6)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from langchain) (9.0.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in d:\\condaa\\envs\\atlas\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\condaa\\envs\\atlas\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\condaa\\envs\\atlas\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\subodh\\appdata\\roaming\\python\\python313\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (24.2)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from requests<3,>=2->langchain) (2.3.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\subodh\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\condaa\\envs\\atlas\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.15,!=0.3.16,!=0.3.17,!=0.3.18,!=0.3.19,!=0.3.2,!=0.3.20,!=0.3.21,!=0.3.22,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# ATLAS : Academic Task and Learning Agent System\n",
    "\n",
    "# ATLAS demonstrates how to build an intelligent multi-agent system that transforms the way students manage their academic life. Using LangGraph's workflow framework, we'll create a network of specialized AI agents that work together to provide personalized academic support, from automated scheduling to intelligent lectures summarization.\n",
    "\n",
    "# Key Components\n",
    "\n",
    "# Coordinator Agent: Orchestrates the interaction between specialized agents and manages the overall system state\n",
    "# Planner Agent: Handles calendar integration and schedule optimization\n",
    "# Notewriter Agent: Processes academic content and generates study materials\n",
    "# Advisor Agent: Provides personalized learning and time management advices\n",
    "\n",
    "\n",
    "%pip install langgraph langchain langchain-openai openai python-dotenv capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement python3-dev (from versions: none)\n",
      "ERROR: No matching distribution found for python3-dev\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting graphvizNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for pygraphviz (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [48 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-313\\pygraphviz\n",
      "      copying pygraphviz\\agraph.py -> build\\lib.win-amd64-cpython-313\\pygraphviz\n",
      "      copying pygraphviz\\graphviz.py -> build\\lib.win-amd64-cpython-313\\pygraphviz\n",
      "      copying pygraphviz\\scraper.py -> build\\lib.win-amd64-cpython-313\\pygraphviz\n",
      "      copying pygraphviz\\testing.py -> build\\lib.win-amd64-cpython-313\\pygraphviz\n",
      "      copying pygraphviz\\__init__.py -> build\\lib.win-amd64-cpython-313\\pygraphviz\n",
      "      creating build\\lib.win-amd64-cpython-313\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_attribute_defaults.py -> build\\lib.win-amd64-cpython-313\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_clear.py -> build\\lib.win-amd64-cpython-313\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_close.py -> build\\lib.win-amd64-cpython-313\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_drawing.py -> build\\lib.win-amd64-cpython-313\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_edge_attributes.py -> build\\lib.win-amd64-cpython-313\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_graph.py -> build\\lib.win-amd64-cpython-313\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_html.py -> build\\lib.win-amd64-cpython-313\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_layout.py -> build\\lib.win-amd64-cpython-313\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_node_attributes.py -> build\\lib.win-amd64-cpython-313\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_readwrite.py -> build\\lib.win-amd64-cpython-313\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_repr_mimebundle.py -> build\\lib.win-amd64-cpython-313\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_scraper.py -> build\\lib.win-amd64-cpython-313\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_string.py -> build\\lib.win-amd64-cpython-313\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_subgraph.py -> build\\lib.win-amd64-cpython-313\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\test_unicode.py -> build\\lib.win-amd64-cpython-313\\pygraphviz\\tests\n",
      "      copying pygraphviz\\tests\\__init__.py -> build\\lib.win-amd64-cpython-313\\pygraphviz\\tests\n",
      "      running egg_info\n",
      "      writing pygraphviz.egg-info\\PKG-INFO\n",
      "      writing dependency_links to pygraphviz.egg-info\\dependency_links.txt\n",
      "      writing top-level names to pygraphviz.egg-info\\top_level.txt\n",
      "      reading manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
      "      reading manifest template 'MANIFEST.in'\n",
      "      warning: no files found matching '*.swg'\n",
      "      warning: no files found matching '*.png' under directory 'doc'\n",
      "      warning: no files found matching '*.html' under directory 'doc'\n",
      "      warning: no files found matching '*.txt' under directory 'doc'\n",
      "      warning: no files found matching '*.css' under directory 'doc'\n",
      "      warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "      warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
      "      warning: no previously-included files matching '.svn' found anywhere in distribution\n",
      "      no previously-included directories found matching 'doc\\build'\n",
      "      adding license file 'LICENSE'\n",
      "      writing manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
      "      copying pygraphviz\\graphviz.i -> build\\lib.win-amd64-cpython-313\\pygraphviz\n",
      "      copying pygraphviz\\graphviz_wrap.c -> build\\lib.win-amd64-cpython-313\\pygraphviz\n",
      "      running build_ext\n",
      "      building 'pygraphviz._graphviz' extension\n",
      "      error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pygraphviz\n",
      "ERROR: Failed to build installable wheels for some pyproject.toml based projects (pygraphviz)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pygraphviz\n",
      "  Using cached pygraphviz-1.14.tar.gz (106 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Using cached graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "Building wheels for collected packages: pygraphviz\n",
      "  Building wheel for pygraphviz (pyproject.toml): started\n",
      "  Building wheel for pygraphviz (pyproject.toml): finished with status 'error'\n",
      "Failed to build pygraphviz\n"
     ]
    }
   ],
   "source": [
    "## Graph Visualization\n",
    "%pip install python3-dev graphviz libgraphviz-dev pkg-config\n",
    "%pip install graphviz pygraphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from functools import reduce\n",
    "from typing import Annotated, List , Dict, TypedDict, Literal, Optional, Callable,  Set, Tuple, Any, Union,  TypeVar\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import asyncio\n",
    "from pydantic import BaseModel, Field\n",
    "from operator import add\n",
    "from IPython.display import Image, display\n",
    "import json \n",
    "import re\n",
    "import os\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, BaseMessage\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, Graph, END , START\n",
    "\n",
    "\n",
    "# Pretty Markdown Output\n",
    "from rich.console import Console\n",
    "from rich.markdown import Markdown\n",
    "from rich.panel import Panel\n",
    "from rich.text import Text\n",
    "from rich import box\n",
    "from rich.style import Style \n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key configured: True\n"
     ]
    }
   ],
   "source": [
    "def configure_api_keys():\n",
    "    \"\"\"Configure and verify API keys for LLM services.\"\"\"\n",
    "    load_dotenv()\n",
    "    api_key = os.getenv(\"NEMOTRON_4_340B_INSTRUCT_KEY\")\n",
    "\n",
    "   \n",
    "    is_configured = bool(os.getenv(\"NEMOTRON_4_340B_INSTRUCT_KEY\"))\n",
    "    print(f\"API Key configured: {is_configured}\")\n",
    "    return is_configured\n",
    "\n",
    "api_configured = configure_api_keys()\n",
    "if not api_configured:\n",
    "    print(\"\\nAPI key not found. Please ensure you have:\")\n",
    "    print(\"1. Set up your API key in Google Colab secrets, or\")\n",
    "    print(\"2. Created a .env file with NEMOTRON_4_340B_INSTRUCT_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the AcademicState class to hold the workflow's state.\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "def dict_reducer(dict1: Dict[str,Any], dict2: Dict[str,Any]) -> Dict[str,Any]:\n",
    "    \"\"\"\n",
    "    Merge two dictionaries recursively\n",
    "\n",
    "    Example:\n",
    "    dict1 = {\"a\": {\"x\": 1}, \"b\": 2}\n",
    "    dict2 = {\"a\": {\"y\": 2}, \"c\": 3}\n",
    "    result = {\"a\": {\"x\": 1, \"y\": 2}, \"b\": 2, \"c\": 3}\n",
    "    \"\"\"\n",
    "    merged = dict1.copy()\n",
    "    for key, value in dict2.items():\n",
    "        if key in merged and isinstance(merged[key], dict) and isinstance(value, dict):\n",
    "            merged[key] = dict_reducer(merged[key], value)\n",
    "        else:\n",
    "            merged[key] = value\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AcademicState(TypedDict):\n",
    "    \"\"\"Master state container for the academic assistance system\"\"\"\n",
    "    messages : Annotated[List[BaseMessage],add] # Conversation history\n",
    "    profile : Annotated[Dict, dict_reducer]     # Student information\n",
    "    calendar : Annotated[Dict, dict_reducer]    # Scheduled events\n",
    "    tasks : Annotated[Dict, dict_reducer]       # To-do items and assignments\n",
    "    results : Annotated[Dict[str,Any], dict_reducer]       # Operation outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Initialization\n",
    "# Key Differences:\n",
    "\n",
    "# 1. Concurrency Model\n",
    "#   - AsyncOpenAI: Asynchronous operations using `async/await`\n",
    "#   - OpenAI: Synchronous operations that block execution\n",
    "\n",
    "# 2. Use Cases\n",
    "#   - AsyncOpenAI: High throughput, non-blocking operations\n",
    "#   - OpenAI: Simple sequential requests, easier debugging\n",
    "\n",
    "class LLMConfig:\n",
    "    \"\"\"Configuration settings for the LLM.\"\"\"\n",
    "    base_url = \"https://integrate.api.nvidia.com/v1\"\n",
    "    model: str = \"nvidia/nemotron-4-340b-instruct\"\n",
    "    max_tokens: int = 1024\n",
    "    default_temp : float = 0.5\n",
    "\n",
    "class NeMoLLaMa:\n",
    "    \"\"\"\n",
    "    A class to interact with NVIDIA's nemotron-4-340b-instruct model through their API\n",
    "    This implementation uses AsyncOpenAI client for asynchronous operations\n",
    "    \"\"\"\n",
    "    def __init__(self, api_key: str):\n",
    "        \"\"\"Initialize NeMoLLaMa with API key.\n",
    "\n",
    "        Args:\n",
    "            api_key (str): NVIDIA API authentication key\n",
    "        \"\"\"\n",
    "        self.config = LLMConfig()\n",
    "        self.client = AsyncOpenAI(\n",
    "            base_url=self.config.base_url,\n",
    "            api_key=api_key\n",
    "        )\n",
    "        self.is_authenticated = False\n",
    "\n",
    "    async def check_auth(self)->bool:\n",
    "        \"\"\"Verify API authentication with test request.\n",
    "\n",
    "        Returns:\n",
    "            bool: Authentication status\n",
    "\n",
    "        Example:\n",
    "            >>> is_valid = await llm.check_auth()\n",
    "            >>> print(f\"Authenticated: {is_valid}\")\n",
    "        \"\"\"\n",
    "        test_message = [{\"role\":\"user\",\"content\":\"test\"}]\n",
    "        try:\n",
    "            await self.agenerate(test_message, temperature=0.1)\n",
    "            self.is_authenticated = True\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Authentication failed: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    async def agenerate(self, messages: List[Dict], temperature: Optional[float]= None)-> str:\n",
    "        \"\"\"Generate text using NeMo LLaMa model.\n",
    "\n",
    "        Args:\n",
    "            messages: List of message dicts with 'role' and 'content'\n",
    "            temperature: Sampling temperature (0.0 to 1.0, default from config)\n",
    "\n",
    "        Returns:\n",
    "            str: Generated text response\n",
    "\n",
    "        Example:\n",
    "            >>> messages = [\n",
    "            ...     {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "            ...     {\"role\": \"user\", \"content\": \"Plan my study schedule\"}\n",
    "            ... ]\n",
    "            >>> response = await llm.agenerate(messages, temperature=0.7)\n",
    "        \"\"\"\n",
    "        completion = await self.client.chat.completions.create(\n",
    "            model = self.config.model,\n",
    "            messages = messages,\n",
    "            temperature=temperature or self.config.default_temp,\n",
    "            max_tokens=self.config.max_tokens,\n",
    "            stream = False\n",
    "        )\n",
    "        return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataManager\n",
    "# A centralized data management system for AI agents to handle multiple data sources.\n",
    "\n",
    "# This class serves as a unified interface for accessing and managing different types of\n",
    "# structured data (profiles, calendars, tasks) that an AI agent might need to process.\n",
    "# It handles data loading, parsing, and provides methods for intelligent filtering and retrieval.\n",
    "\n",
    "class DataManager:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize data storage containers.\n",
    "        All data sources start as None until explicitly loaded through load_data().\n",
    "        \"\"\"\n",
    "        self.profile_data = None\n",
    "        self.calendar_data = None\n",
    "        self.tasks_data = None\n",
    "\n",
    "    def load_data(self, profile_json:str, calendar_json:str, task_json:str):\n",
    "        \"\"\"\n",
    "        Load and parse multiple JSON data sources simultaneously.\n",
    "\n",
    "        Args:\n",
    "            profile_json (str): JSON string containing user profile information\n",
    "            calendar_json (str): JSON string containing calendar events\n",
    "            task_json (str): JSON string containing task/todo items\n",
    "\n",
    "        Note: This method expects valid JSON strings. Any parsing errors will propagate up.\n",
    "        \"\"\"\n",
    "        self.profile_data = json.loads(profile_json)\n",
    "        self.calendar_data = json.loads(calendar_json)\n",
    "        self.tasks_data = json.loads(task_json)\n",
    "\n",
    "    def get_student_profile(self, student_id:str)-> Dict:\n",
    "        \"\"\"\n",
    "        Retrieve a specific student's profile using their unique identifier.\n",
    "\n",
    "        Args:\n",
    "            student_id (str): Unique identifier for the student\n",
    "\n",
    "        Returns:\n",
    "            Dict: Student profile data if found, None otherwise\n",
    "\n",
    "        Implementation Note:\n",
    "            Uses generator expression with next() for efficient search through profiles,\n",
    "            avoiding full list iteration when possible.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.profile_data:\n",
    "            return next((p for p in self.profile_data[\"profiles\"] if p[\"id\"] == student_id), None)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def parse_datetime(self, dt_str:str)-> datetime:\n",
    "        \"\"\"\n",
    "        Smart datetime parser that handles multiple formats and ensures UTC timezone.\n",
    "\n",
    "        Args:\n",
    "            dt_str (str): DateTime string in ISO format, with or without timezone\n",
    "\n",
    "        Returns:\n",
    "            datetime: Parsed datetime object in UTC timezone\n",
    "\n",
    "        Implementation Note:\n",
    "            Handles both timezone-aware and naive datetime strings by:\n",
    "            1. First attempting to parse with timezone information\n",
    "            2. Falling back to assuming UTC if no timezone is specified\n",
    "        \"\"\"\n",
    "        try :\n",
    "            # First attempt: Parse ISO format with timezone\n",
    "            dt = datetime.fromisoformat(dt_str.replace('Z', '+00:00'))\n",
    "            return dt.astimezone(timezone.utc)\n",
    "        except ValueError:\n",
    "            # Fallback: Assume UTC if no timezone provided\n",
    "            dt = datetime.fromisoformat(dt_str)\n",
    "            return dt.replace(tzinfo=timezone.utc)\n",
    "        \n",
    "    def get_upcoming_events(self, days:int =7)-> List[Dict]:\n",
    "        \"\"\"\n",
    "        Intelligently filter and retrieve upcoming calendar events within a specified timeframe.\n",
    "\n",
    "        Args:\n",
    "            days (int): Number of days to look ahead (default: 7)\n",
    "\n",
    "        Returns:\n",
    "            List[Dict]: List of upcoming events, chronologically ordered\n",
    "\n",
    "        Implementation Note:\n",
    "            - Uses UTC timestamps for consistent timezone handling\n",
    "            - Implements error handling for malformed event data\n",
    "            - Only includes events that start in the future up to the specified timeframe\n",
    "        \"\"\"\n",
    "        if not self.calendar_data:\n",
    "            return []\n",
    "        \n",
    "        now = datetime.now(timezone.utc)\n",
    "        future = now + timedelta(days=days)\n",
    "        events = []\n",
    "        for event in self.calendar_data.get(\"events\",[]):\n",
    "            try:\n",
    "                start_time = self.parse_datetime(event[\"start\"][\"dateTime\"])\n",
    "                if now <= start_time <= future:\n",
    "                    events.append(event)\n",
    "            except (KeyError, ValueError) as e:\n",
    "                print(f\"Warning: Could not process event due to {str(e)}\")\n",
    "                continue\n",
    "        return events\n",
    "    \n",
    "    def get_active_tasks(self)-> List[Dict]:\n",
    "        \"\"\"\n",
    "        Retrieve and filter active tasks, enriching them with parsed datetime information.\n",
    "\n",
    "        Returns:\n",
    "            List[Dict]: List of active tasks with parsed due dates\n",
    "\n",
    "        Implementation Note:\n",
    "            - Filters for tasks that are:\n",
    "              1. Not completed (\"needsAction\" status)\n",
    "              2. Due in the future\n",
    "            - Enriches task objects with parsed datetime for easier processing\n",
    "            - Implements robust error handling for malformed task data\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.tasks_data:\n",
    "            return []\n",
    "        \n",
    "        now = datetime.now(timezone.utc)\n",
    "        active_tasks = []\n",
    "\n",
    "        for task in self.tasks_data.get(\"tasks\",[]):\n",
    "            try:\n",
    "                due_date = self.parse_datetime(task[\"due\"])\n",
    "                if task[\"status\"] == \"needsAction\" and due_date > now:\n",
    "                    # Enrich task object with parsed datetime\n",
    "                    task[\"due_datetime\"] = due_date\n",
    "                    active_tasks.append(task)\n",
    "            except (KeyError, ValueError) as e:\n",
    "                print(f\"Warning: Could not process task due to {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        return active_tasks\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.NeMoLLaMa object at 0x0000029204A117F0>\n"
     ]
    }
   ],
   "source": [
    "llm = NeMoLLaMa(api_key=os.getenv(\"NEMOTRON_4_340B_INSTRUCT_KEY\"))\n",
    "data_manager = DataManager()\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Executor\n",
    "# Orchestrates the concurrent execution of multiple specialized AI agents.\n",
    "\n",
    "# This class implements a sophisticated execution pattern that allows multiple AI agents\n",
    "# to work together, either sequentially or concurrently, based on a coordination analysis.\n",
    "# It handles agent initialization, concurrent execution, error handling, and fallback strategies.\n",
    "\n",
    "class AgentExecutor:\n",
    "\n",
    "    def __init(self, llm):\n",
    "        \"\"\"\n",
    "        Initialize the executor with a language model and create agent instances.\n",
    "\n",
    "        Args:\n",
    "            llm: Language model instance to be used by all agents\n",
    "\n",
    "        Implementation Note:\n",
    "            - Creates a dictionary of specialized agents, each initialized with the same LLM\n",
    "            - Supports multiple agent types: PLANNER (default), NOTEWRITER, and ADVISOR\n",
    "            - Agents are instantiated once and reused across executions\n",
    "        \"\"\"\n",
    "        self.llm = llm\n",
    "        self.agents = {\n",
    "            \"PLANNER\" : PlannerAgent(llm),  # Strategic planning agent\n",
    "            \"NOTEWRITER\" : NoteWriterAgent(llm),    # Documentation agent\n",
    "            \"ADVISOR\" : AdvisorAgent(llm)   # Academic advice agent\n",
    "        }\n",
    "\n",
    "    async def execute(self, state: AcademicState)-> Dict:\n",
    "        \"\"\"\n",
    "        Orchestrates concurrent execution of multiple AI agents based on analysis results.\n",
    "\n",
    "        This method implements a sophisticated execution pattern:\n",
    "        1. Reads coordination analysis to determine required agents\n",
    "        2. Groups agents for concurrent execution\n",
    "        3. Executes agent groups in parallel\n",
    "        4. Handles failures gracefully with fallback mechanisms\n",
    "\n",
    "        Args:\n",
    "            state (AcademicState): Current academic state containing analysis results\n",
    "\n",
    "        Returns:\n",
    "            Dict: Consolidated results from all executed agents\n",
    "\n",
    "        Implementation Details:\n",
    "        ---------------------\n",
    "        1. Analysis Interpretation:\n",
    "           - Extracts coordination analysis from state\n",
    "           - Determines required agents and their concurrent execution groups\n",
    "\n",
    "        2. Concurrent Execution Pattern:\n",
    "           - Processes agents in groups that can run in parallel\n",
    "           - Uses asyncio.gather() for concurrent execution within each group\n",
    "           - Only executes agents that are both required and available\n",
    "\n",
    "        3. Result Management:\n",
    "           - Collects and processes results from each concurrent group\n",
    "           - Filters out failed executions (exceptions)\n",
    "           - Formats successful results into a structured output\n",
    "\n",
    "        4. Fallback Mechanisms:\n",
    "           - If no results are gathered, falls back to PLANNER agent\n",
    "           - Provides emergency fallback plan in case of complete failure\n",
    "\n",
    "        Error Handling:\n",
    "        --------------\n",
    "        - Catches and handles exceptions at multiple levels:\n",
    "          * Individual agent execution failures don't affect other agents\n",
    "          * System-level failures trigger emergency fallback\n",
    "        - Maintains system stability through graceful degradation\n",
    "        \"\"\"\n",
    "        try:\n",
    "           # Extract coordination analysis from state\n",
    "           analysis = state[\"results\"].get(\"coordinator_analysis\", {})\n",
    "\n",
    "           # Determine execution requirements\n",
    "           required_agents = analysis.get(\"required_agents\", [\"PLANNER\"])# PLANNER as default\n",
    "           concurrent_groups = analysis.get(\"concurrent_groups\", []) # Groups for parallel execution\n",
    "        \n",
    "           # Initialize results container\n",
    "           results = {}\n",
    "\n",
    "           # Process each concurrent group sequentially\n",
    "           for group in concurrent_groups:\n",
    "               # Prepare concurrent tasks for current group\n",
    "               tasks = []\n",
    "               for agent_name in group:\n",
    "                   # Validate agent availability and requirement\n",
    "                   if agent_name in required_agents and agent_name in self.agents:\n",
    "                       tasks.append(self.agents[agent_name](state))\n",
    "               # Execute group tasks concurrently if any exist\n",
    "               if tasks:\n",
    "                   # Gather results from concurrent execution\n",
    "                   group_results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "                   # Process successful results only\n",
    "                   for agent_name, result in zip(group, group_results):\n",
    "                       if not isinstance(result, Exception):\n",
    "                           results[agent_name.lower()] = result\n",
    "\n",
    "           # Implement fallback strategy if no results were obtained\n",
    "           if not results and \"PLANNER\" in self.agents:\n",
    "               planner_result = await self.agents[\"PLANNER\"](state)\n",
    "               results[\"planner\"] = planner_result\n",
    "\n",
    "           print(\"agent_outputs\", results)\n",
    "           # Return structured results\n",
    "           return {\n",
    "                \"results\": {\n",
    "                    \"agent_outputs\": results\n",
    "                }\n",
    "           }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Execution error: {e}\")\n",
    "            # Emergency fallback with minimal response\n",
    "            return {\n",
    "                \"results\": {\n",
    "                    \"agent_outputs\": {\n",
    "                        \"planner\": {\n",
    "                            \"plan\": \"Emergency fallback plan: Please try again or contact support.\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Action and Output Models\n",
    "# Defines the structure for agent actions and outputs using Pydantic models. These models ensure type safety and validation for agent operations.\n",
    "\n",
    "class AgentAction(BaseModel):\n",
    "    \"\"\"\n",
    "    Model representing an agent's action decision.\n",
    "\n",
    "    Attributes:\n",
    "        action (str): The specific action to be taken (e.g., \"search_calendar\", \"analyze_tasks\")\n",
    "        thought (str): The reasoning process behind the action choice\n",
    "        tool (Optional[str]): The specific tool to be used for the action (if needed)\n",
    "        action_input (Optional[Dict]): Input parameters for the action\n",
    "\n",
    "    Example:\n",
    "        >>> action = AgentAction(\n",
    "        ...     action=\"search_calendar\",\n",
    "        ...     thought=\"Need to check schedule conflicts\",\n",
    "        ...     tool=\"calendar_search\",\n",
    "        ...     action_input={\"date_range\": \"next_week\"}\n",
    "        ... )\n",
    "    \"\"\"\n",
    "    action: str # Required action to be performed\n",
    "    thought: str    # Reasoning behind the action\n",
    "    tool: Optional[str] = None  # Optional tool specification\n",
    "    action_input: Optional[Dict] = None # Optional input parameters\n",
    "\n",
    "class AgentOutput(BaseModel):\n",
    "    \"\"\"\n",
    "    Model representing the output from an agent's action.\n",
    "\n",
    "    Attributes:\n",
    "        observation (str): The result or observation from executing the action\n",
    "        output (Dict): Structured output data from the action\n",
    "\n",
    "    Example:\n",
    "        >>> output = AgentOutput(\n",
    "        ...     observation=\"Found 3 free time slots next week\",\n",
    "        ...     output={\n",
    "        ...         \"free_slots\": [\"Mon 2PM\", \"Wed 10AM\", \"Fri 3PM\"],\n",
    "        ...         \"conflicts\": []\n",
    "        ...     }\n",
    "        ... )\n",
    "    \"\"\"\n",
    "    observation: str  # Result or observation from the action\n",
    "    output: Dict     # Structured output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReACT agent\n",
    "# What's actually is ReACT?\n",
    "\n",
    "# ReACT (Reasoning and Acting) is a framework that combines reasoning and acting in an iterative process. It enables LLMs to approach complex tasks by breaking them down into:\n",
    "\n",
    "# (Re)act: Take an action based on observations and tools\n",
    "# (Re)ason: Think about what to do next\n",
    "# (Re)flect: Learn from the outcome\n",
    "# Example Flow:\n",
    "\n",
    "# Thought: Need to check student's schedule for study time\n",
    "# Action: search_calendar\n",
    "# Observation: Found 2 free hours tomorrow morning\n",
    "# Thought: Student prefers morning study, this is optimal\n",
    "# Action: analyze_tasks\n",
    "# Observation: Has 3 pending assignments\n",
    "# Plan: Schedule morning study session for highest priority task\n",
    "\n",
    "class ReActAgent:\n",
    "    \"\"\"\n",
    "        Base class for ReACT-based agents implementing reasoning and action capabilities.\n",
    "\n",
    "        Features:\n",
    "        - Tool management for specific actions\n",
    "        - Few-shot learning examples\n",
    "        - Structured thought process\n",
    "        - Action execution framework\n",
    "    \"\"\"\n",
    "    def __init__(self, llm):\n",
    "        \"\"\"\n",
    "        Initialize the ReActAgent with language model and available tools\n",
    "\n",
    "        Args:\n",
    "            llm: Language model instance for agent operations\n",
    "        \"\"\"\n",
    "        self.llm = llm\n",
    "        # Storage for few-shot examples to guide the agent\n",
    "        self.few_shot_examples = []\n",
    "\n",
    "        # Dictionary of available tools with their corresponding methods\\\n",
    "        self.tools = {\n",
    "          \"search_calendar\": self.search_calendar,      # Calendar search functionality\n",
    "          \"analyze_tasks\": self.analyze_tasks,          # Task analysis functionality\n",
    "          \"check_learning_style\": self.check_learning_style,  # Learning style assessment\n",
    "          \"check_performance\": self.check_performance   # Academic performance checking\n",
    "        }\n",
    "    \n",
    "    async def search_calendar(self, state: AcademicState) -> List[Dict]:\n",
    "      \"\"\"\n",
    "      Search for upcoming calendar events\n",
    "\n",
    "      Args:\n",
    "          state (AcademicState): Current academic state\n",
    "\n",
    "      Returns:\n",
    "          List[Dict]: List of upcoming calendar events\n",
    "      \"\"\"\n",
    "      # Get events from calendar or empty list if none exist\n",
    "      events = state[\"calendar\"].get(\"events\", [])\n",
    "      # Get current time in UTC\n",
    "      now = datetime.now(timezone.utc)\n",
    "      # Filter and return only future events\n",
    "      return [e for e in events if datetime.fromisoformat(e[\"start\"][\"dateTime\"]) > now]\n",
    "\n",
    "    async def analyze_tasks(self, state: AcademicState) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Analyze academic tasks from the current state\n",
    "\n",
    "        Args:\n",
    "            state (AcademicState): Current academic state\n",
    "\n",
    "        Returns:\n",
    "            List[Dict]: List of academic tasks\n",
    "        \"\"\"\n",
    "        # Return tasks or empty list if none exist\n",
    "        return state[\"tasks\"].get(\"tasks\", [])\n",
    "\n",
    "    async def check_learning_style(self, state: AcademicState) -> AcademicState:\n",
    "            \"\"\"\n",
    "            Retrieve student's learning style and study patterns\n",
    "\n",
    "            Args:\n",
    "                state (AcademicState): Current academic state\n",
    "\n",
    "            Returns:\n",
    "                AcademicState: Updated state with learning style analysis\n",
    "            \"\"\"\n",
    "            # Get user profile from state\n",
    "            profile = state[\"profile\"]\n",
    "\n",
    "            # Get learning preferences\n",
    "            learning_data = {\n",
    "                \"style\": profile.get(\"learning_preferences\", {}).get(\"learning_style\", {}),\n",
    "                \"patterns\": profile.get(\"learning_preferences\", {}).get(\"study_patterns\", {})\n",
    "            }\n",
    "\n",
    "            # Add to results in state\n",
    "            if \"results\" not in state:\n",
    "                state[\"results\"] = {}\n",
    "            state[\"results\"][\"learning_analysis\"] = learning_data\n",
    "\n",
    "            return state\n",
    "\n",
    "    async def check_performance(self, state: AcademicState) -> AcademicState:\n",
    "            \"\"\"\n",
    "            Check current academic performance across courses\n",
    "\n",
    "            Args:\n",
    "                state (AcademicState): Current academic state\n",
    "\n",
    "            Returns:\n",
    "                AcademicState: Updated state with performance analysis\n",
    "            \"\"\"\n",
    "            # Get user profile from state\n",
    "            profile = state[\"profile\"]\n",
    "\n",
    "            # Get course information\n",
    "            courses = profile.get(\"academic_info\", {}).get(\"current_courses\", [])\n",
    "\n",
    "            # Add to results in state\n",
    "            if \"results\" not in state:\n",
    "                state[\"results\"] = {}\n",
    "            state[\"results\"][\"performance_analysis\"] = {\"courses\": courses}\n",
    "\n",
    "            return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinator Agent\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
